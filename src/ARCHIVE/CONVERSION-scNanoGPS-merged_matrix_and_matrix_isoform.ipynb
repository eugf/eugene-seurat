{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/4/24\n",
    "\n",
    "LAST UPDATED: 1/6/25\n",
    "\n",
    "By Eugene Fong\n",
    "\n",
    "# #* TODO - add log?\n",
    "\n",
    "# GOAL(S)\n",
    "- Merge the resulting scNanoGPS matrix and matrix_isoform files together\n",
    "\n",
    "- Input files needed:\n",
    "  - matrix.tsv\n",
    "  - matrix_isoform.tsv\n",
    "\n",
    "- Output files created:\n",
    "  - merge_matrix_and_matrix_isoform.tsv\n",
    "\n",
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.io import mmwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA\n",
    "\n",
    "See `/scNanoGPS_res` folder for a list of processed sample outputs at:\n",
    "\n",
    "    /data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FILE PATHS - CHANGE THIS!!!\n",
    "# Input paths - look inside the scNanoGPS output folder (`/scNanoGPS_res`) by patient ID until you reach the parent folder that holds the matrix.tsv + matrix_isoform.tsv files\n",
    "# scNanoGPS_output_dir = '/data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res/SH-04-08_singlecell_LR/20240321-1/20240321'\n",
    "scNanoGPS_output_dir = '/data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res/SH-06-25_singlecell_LR/20241105-2/20241105'\n",
    "# scNanoGPS_output_dir = '/data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res/SH-07-46_singlecell_LR/20241105-1/20241105'\n",
    "# scNanoGPS_output_dir = '/data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res/SH-92-05_singlecell_LR/20240314-1/20240314'\n",
    "# scNanoGPS_output_dir = '/data/CARDPB/data/snRNA_longread/scNanoGPS-neuro/scNanoGPS_res/UMARY_4546_FTX_singlecell_LR/20240321-1/20240321'\n",
    "\n",
    "# From there, create the paths for the matrix and matrix isoform files\n",
    "file_path_matrix            = os.path.join(scNanoGPS_output_dir, 'matrix.tsv')\n",
    "file_path_matrix_isoform    = os.path.join(scNanoGPS_output_dir, 'matrix_isoform.tsv')\n",
    "\n",
    "# CHECK\n",
    "print('scNanoGPS_output_dir     =', scNanoGPS_output_dir)\n",
    "print('file_path_matrix         =', file_path_matrix)\n",
    "print('file_path_matrix_isoform =', file_path_matrix_isoform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output dir\n",
    "output_dir = '/data/CARDPB/data/snRNA_longread/eugene-seurat/output/merged'\n",
    "print('output_dir =', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the patient ID\n",
    "id = os.path.basename(os.path.dirname(os.path.dirname(scNanoGPS_output_dir)))\n",
    "print('id =', id)\n",
    "\n",
    "# ALT - better way\n",
    "separators = ['_FTX_singlecell', '_singlecell']\n",
    "split_id = re.split('|'.join(separators), id)[0]\n",
    "\n",
    "# CHECK\n",
    "print('split_id =', split_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get today's date\n",
    "current_date = datetime.date.today()\n",
    "print('current_date =', current_date)\n",
    "\n",
    "formatted_date = current_date.strftime(\"%Y%m%d\")\n",
    "print('formatted_date =', formatted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique output folders based on the patient ID and date\n",
    "sample_dir = os.path.join(output_dir, split_id, formatted_date)\n",
    "print('sample_dir =', sample_dir)\n",
    "\n",
    "# Start a counter for repeated folders\n",
    "counter = 0\n",
    "   \n",
    "# CHECK - if the path link exists as text, adjust name as needed\n",
    "if os.path.exists(sample_dir):\n",
    "    print(f\"The directory '{sample_dir}' exists.\")\n",
    "    new_sample_dir = sample_dir + '-' + str(counter)\n",
    "    \n",
    "    # Increment on the date folder\n",
    "    while os.path.exists(new_sample_dir):\n",
    "        counter += 1\n",
    "        print('counter =', counter)\n",
    "        new_sample_dir = sample_dir + '-' + str(counter)\n",
    "        print('new_sample_dir INSIDE IF BLOCK =', new_sample_dir)\n",
    "    \n",
    "    # Reset this variable to call later\n",
    "    sample_dir = new_sample_dir\n",
    "\n",
    "else:\n",
    "    print(f\"The directory '{sample_dir}' does not exist\")\n",
    "\n",
    "# Make the new directory \n",
    "os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full ID to text file\n",
    "output_id_txt = os.path.join(sample_dir, 'id.txt')\n",
    "\n",
    "# Open file to write and save ID\n",
    "with open(output_id_txt, 'w+') as file:\n",
    "    file.write(id)\n",
    "    # file.write(split_id)\n",
    "\n",
    "print(f'ID written to: {output_id_txt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTPUT PATHS\n",
    "# Save file as `merged_matrix_and_matrix_isoform.tsv`\n",
    "file_path_merged_matrix_and_matrix_isoform = os.path.join(sample_dir, 'merged_matrix_and_matrix_isoform.tsv')\n",
    "\n",
    "# TEST - subset of 5 rows file\n",
    "# Save file as `merged_matrix_and_matrix_isoform.tsv`\n",
    "file_path_merged_matrix_and_matrix_isoform_5 = os.path.join(sample_dir, 'merged_matrix_and_matrix_isoform_5.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD - matrix file into a Pandas DF\n",
    "df_matrix = pd.read_csv(\n",
    "    file_path_matrix, \n",
    "    sep = '\\t',     # For TSV file\n",
    "    skiprows = 0,   # 1st row is metadata, skip it (index = 0)\n",
    "    header = 1      # Header begins on the 2nd row (index = 1)\n",
    "    )\n",
    "\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "print('df_matrix.shape =', df_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLANNING\n",
    "\n",
    "By row/col\n",
    "\n",
    "```\n",
    "Row 0   = command (DROP)\n",
    "Row 1   = header\n",
    "Row 2+  = Transcripts (ENS ID #s) (KEEP)\n",
    "\n",
    "###########################\n",
    "\n",
    "Col 0       = Geneid\n",
    "Col 1 - 5   = (DROP)\n",
    "Col 6       = gene_name (KEEP)\n",
    "Col 7+      = barcodes (KEEP)\n",
    "```\n",
    "\n",
    "### Steps overview\n",
    "\n",
    "- KEEP: Geneid, gene_name, and the rest of the barcodes\n",
    "- DROP: in betw cols\n",
    "- Then merge on the barcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these cols from the DFs\n",
    "df_matrix_drop = df_matrix.drop(\n",
    "    columns = ['Chr', 'Start', 'End', 'Strand', 'Length'], \n",
    "    inplace = False\n",
    "    )\n",
    "\n",
    "df_matrix_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD - matrix isoform file into a Pandas DF\n",
    "df_isoform = pd.read_csv(\n",
    "    file_path_matrix_isoform, \n",
    "    sep = '\\t',     # For TSV file\n",
    "    )\n",
    "\n",
    "df_isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "df_isoform_shape_initial = df_isoform.shape[1]\n",
    "print('df_isoform_shape_initial =', df_isoform_shape_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RENAME - missing header col\n",
    "df_isoform = df_isoform.rename(columns = {'Unnamed: 0': 'Geneid'})\n",
    "df_isoform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #? Q) Do I need to rebuild the `gene_name` col?\n",
    "### #? A) Maybe? Copy and paste it over entirely\n",
    "\n",
    "NOTES: This col's format:\n",
    "\n",
    "- <gene_name>_ENSEMBLE###.#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (MOVED from lower down barcodes section up here)\n",
    "\n",
    "### Create the `barcodes.tsv` file\n",
    "\n",
    "- Get the 2nd row of the original `matrix.tsv` file (which is now the header row)\n",
    "- Extract all the barcodes, drop the other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop the first 2 rows (already done during import)\n",
    "- Get the barcode column names as a list\n",
    "- Extract the columns I want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD - matrix file into a Pandas DF\n",
    "df_matrix_header = pd.read_csv(\n",
    "    file_path_matrix, \n",
    "    sep = '\\t',     # For TSV file\n",
    "    skiprows = 1,   # 1st row is metadata, skip it (index = 0)\n",
    "    nrows = 1,      # Only load the 1st row (the header row)\n",
    "    header = None \n",
    "    )\n",
    "\n",
    "df_matrix_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a 1D series\n",
    "header_series = df_matrix_header.squeeze()\n",
    "header_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the initial columns from the header\n",
    "header_series_subset = header_series[7:]\n",
    "header_series_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the initial columns from the header\n",
    "barcodes_matrix_list = header_series[7:].tolist()\n",
    "print('barcodes_matrix_list[:5] =')\n",
    "print(barcodes_matrix_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the 'Geneid\" column and paste it as a new column 'gene_name'\n",
    "df_isoform['gene_name'] = df_isoform['Geneid']\n",
    "\n",
    "# Create a list of just the column names in the order that you want it the genes.tsv file\n",
    "cols = ['Geneid', 'gene_name']\n",
    "cols.extend(barcodes_matrix_list)\n",
    "# print('cols =', cols)\n",
    "\n",
    "# Remake the DF in that order\n",
    "df_isoform = df_isoform[cols]\n",
    "df_isoform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "df_isoform_shape_final = df_isoform.shape[1]\n",
    "print('df_isoform_shape_final =', df_isoform_shape_final)\n",
    "\n",
    "assert df_isoform_shape_final == df_isoform_shape_initial + 1, f'{df_isoform_shape_final} =/= {df_isoform_shape_initial} + 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST BLOCKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST - subset the DF to only 5 rows\n",
    "df_matrix_drop_5 = df_matrix_drop.head(5)\n",
    "df_matrix_drop_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - subset the DF to only 5 rows\n",
    "df_isoform_5 = df_isoform.head(5)\n",
    "df_isoform_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - the col dimensions match up w/the matrix dimensions, great!\n",
    "# Merge all\n",
    "df_merged_5 = pd.merge(df_matrix_drop_5, df_isoform_5, how = 'outer')\n",
    "df_merged_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - EXPORT\n",
    "df_merged_5.to_csv(\n",
    "    file_path_merged_matrix_and_matrix_isoform_5, \n",
    "    sep = '\\t', \n",
    "    index = False, \n",
    "    )\n",
    "\n",
    "print(f\"Saved merged_matrix_and_matrix_isoform_5.tsv to: {file_path_merged_matrix_and_matrix_isoform_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST - RELOAD - matrix file into a Pandas DF\n",
    "df_merged_5 = pd.read_csv(\n",
    "    file_path_merged_matrix_and_matrix_isoform_5, \n",
    "    sep = '\\t',     # For TSV file\n",
    "    )\n",
    "\n",
    "df_merged_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "### Apply to the FULL merged DF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all\n",
    "df_merged = pd.merge(df_matrix_drop, df_isoform, how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - see the NaN's in the gene_name col?\n",
    "df_merged.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - for floats\n",
    "df_merged.iloc[: , 3].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - for dtypes\n",
    "# NOTE - floats mostly + 2 objects, uh oh\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT - as .TSV file\n",
    "\n",
    "Next:\n",
    "\n",
    "- This will be a new merged .TSV file to run thru the rest of the CONVERSION pipeline\n",
    "- run thru the other CONVERSION script\n",
    "- run thru Seurat to see if this works, it might be the gene name col that screws it up, even if I specify to use col 1 since the matrix.tsv file needs to use col 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "df_merged.to_csv(\n",
    "    file_path_merged_matrix_and_matrix_isoform, \n",
    "    sep = '\\t', \n",
    "    index = False, \n",
    "    )\n",
    "\n",
    "print(f'Saved merged_matrix_and_matrix_isoform.tsv to: {file_path_merged_matrix_and_matrix_isoform}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERSION\n",
    "\n",
    "- from merged matrix + matrix_isoform to:\n",
    "  - genes.tsv\n",
    "  - barcodes.tsv\n",
    "  - matrix.mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #* TODO - unnecessary?\n",
    "# # Output dir\n",
    "# output_dir = '/data/CARDPB/data/snRNA_longread/eugene-seurat/output/merged'\n",
    "print('output_dir =', output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD - the merged matrix file \n",
    "df_merged = pd.read_csv(\n",
    "    file_path_merged_matrix_and_matrix_isoform, \n",
    "    sep = '\\t',     # For TSV file\n",
    "    )\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERSION\n",
    "\n",
    "### Create the `genes.tsv` file \n",
    "\n",
    "- Drop the first 2 rows (already done during import)\n",
    "- Extract 2 columns: \n",
    "  - Geneid (the ensemble #s) and \n",
    "  - gene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your desired cols\n",
    "df_gene_id_and_gene_name = df_merged[['Geneid', 'gene_name']]\n",
    "df_gene_id_and_gene_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT - `genes.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path\n",
    "file_path_genes_tsv = os.path.join(sample_dir, 'genes.tsv')\n",
    "\n",
    "# Save file as `genes.tsv`\n",
    "df_gene_id_and_gene_name.to_csv(\n",
    "    file_path_genes_tsv, \n",
    "    sep = '\\t', \n",
    "    index = False, \n",
    "    header = False\n",
    "    )\n",
    "\n",
    "print(f'Saved genes.tsv to: {file_path_genes_tsv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (NOTE: MOVING SOME OF THE BARCODES.TSV CODE UP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the formatting to match examples and our data\n",
    "#* NOTE - add the donor ID at a later step in Seurat instead of here\n",
    "header_series_subset_mod = header_series_subset + '-1'\n",
    "header_series_subset_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT - `barcodes.tsv`\n",
    "\n",
    "#* NOTE - check if the index is still there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path for `barcodes.tsv`\n",
    "file_path_barcodes_tsv = os.path.join(sample_dir, 'barcodes.tsv')\n",
    "\n",
    "# EXPORT - file to `barcodes.tsv`\n",
    "header_series_subset_mod.to_csv(\n",
    "    file_path_barcodes_tsv, \n",
    "    sep = '\\t', \n",
    "    index = False, \n",
    "    header = False\n",
    "    )\n",
    "\n",
    "print(f'Saved barcodes.tsv to: {file_path_barcodes_tsv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the `matrix.mtx` file\n",
    "\n",
    "- Import `matrix.tsv` as a DF, \n",
    "- Get rid of cols from `chr` to `gene_name`, just keep `geneid` and then all the counts cols, \n",
    "- then convert to a sparse matrix format (needs library matrix to convert to DCG matrix)\n",
    "- add dimensions, row, col, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELOAD - merged matrix file w/changes\n",
    "df_merged_no_header = pd.read_csv(\n",
    "    file_path_merged_matrix_and_matrix_isoform, \n",
    "    sep = '\\t',         # For TSV file\n",
    "    skiprows = [0],     # 1st row is header, skip (index = 0),\n",
    "    header = None,      # SKIP header this time\n",
    "    )\n",
    "\n",
    "df_merged_no_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - using the earlier DF with header names \n",
    "cols_to_drop = df_merged.columns[00:2]\n",
    "print('cols_to_drop =', cols_to_drop)\n",
    "\n",
    "# Use the \"full\" DF\n",
    "cols_to_drop = df_merged_no_header.columns[00:2]\n",
    "print('cols_to_drop =', cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY - Drop to those cols in the full DF\n",
    "df_merged_no_header_drop = df_merged_no_header.drop(cols_to_drop, axis = 1)\n",
    "df_merged_no_header_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - compare - are there still 2 object datatypes?\n",
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK - dtypes\n",
    "df_merged_no_header_drop.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT - processed DF to .TSV file\n",
    "\n",
    "Save file as `matrix_dropped.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file\n",
    "file_path_matrix_dropped_tsv = os.path.join(sample_dir, 'matrix_dropped.tsv')\n",
    "\n",
    "# EXPORT - the processed DF to a .TSV file\n",
    "df_merged_no_header_drop.to_csv(\n",
    "    file_path_matrix_dropped_tsv, \n",
    "    sep = '\\t', \n",
    "    index = False, \n",
    "    header = False\n",
    "    )\n",
    "\n",
    "print(f'Saved matrix_dropped.tsv to: {file_path_matrix_dropped_tsv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONVERSION - function to convert the TSV file to a sparse matrix .MTX file\n",
    "\n",
    "NOTES:\n",
    "- having non-numerical data types is a problem... what to do about the header and index?\n",
    "- prolly drop them for the matrix since its in `barcodes.tsv` and `genes.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsv_to_mtx(input_file, output_file):\n",
    "    \n",
    "    # Read the TSV file\n",
    "    df = pd.read_csv(\n",
    "        input_file, \n",
    "        sep = '\\t',             # For TSV file\n",
    "        index_col = None,       # Don't make an index col\n",
    "        header = None,          # Don't make a header row\n",
    "        # low_memory = False,   # WARNING - will slow it down, but prevents type errors from sampling\n",
    "        )\n",
    "    \n",
    "    # Convert DataFrame to numpy array\n",
    "    data = df.to_numpy()\n",
    "    \n",
    "    # Create sparse matrix\n",
    "    sparse_matrix = sparse.csr_matrix(data)\n",
    "    \n",
    "    # Save the sparse matrix to a .mtx file\n",
    "    mmwrite(output_file, sparse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORT - `matrix.mtx` file as a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output file\n",
    "output_file = os.path.join(sample_dir, 'matrix.mtx')\n",
    "\n",
    "# Run conversion function to export to a .MTX file\n",
    "tsv_to_mtx(file_path_matrix_dropped_tsv, output_file)\n",
    "print(f'Saved matrix.mtx to: {output_file}')\n",
    "\n",
    "# NOTE - in the JNB running in `sinteractive` the mem exceeded 160 GB when the code fails, gets up to 100 GB if it works tho, uses less, like ~50 GB from sbatch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
